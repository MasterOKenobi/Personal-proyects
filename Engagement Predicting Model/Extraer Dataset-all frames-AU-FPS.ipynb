{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ac9065-2b8f-4c18-947a-659cc4b13d48",
   "metadata": {},
   "source": [
    "## Importamos librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11dc414d-0a32-4fb5-85e3-3971f6ead82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "620844c4-2902-4f38-9c44-367da53f8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import local_binary_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5ca5f-e035-4617-87af-0f051b4204a1",
   "metadata": {},
   "source": [
    "## Funcion Gaze para el calculo de rotacion de la cabeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0df5277-c50b-4c9e-8272-717d94889823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gazes(image,results):\n",
    "    img_h, img_w, img_c = image.shape\n",
    "    face_3d = []\n",
    "    face_2d = []\n",
    "    for idx, lm in enumerate(results):\n",
    "        if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "            if idx == 1:\n",
    "                nose_2d = (lm.x * img_w, lm.y * img_h)\n",
    "                nose_3d = (lm.x * img_w, lm.y * img_h, lm.z * 3000)\n",
    "\n",
    "            x, y = int(lm.x * img_w), int(lm.y * img_h)\n",
    "\n",
    "            # Get the 2D Coordinates\n",
    "            face_2d.append([x, y])\n",
    "\n",
    "            # Get the 3D Coordinates\n",
    "            face_3d.append([x, y, lm.z])       \n",
    "\n",
    "    # Convert it to the NumPy array\n",
    "    face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "    # Convert it to the NumPy array\n",
    "    face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "    # The camera matrix\n",
    "    focal_length = 1 * img_w\n",
    "\n",
    "    cam_matrix = np.array([ [focal_length, 0, img_h / 2],\n",
    "                            [0, focal_length, img_w / 2],\n",
    "                            [0, 0, 1]])\n",
    "\n",
    "    # The distortion parameters\n",
    "    dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "    # Solve PnP\n",
    "    success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "    # Get rotational matrix\n",
    "    rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "    # Get angles\n",
    "    angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "    # Get the y rotation degree\n",
    "    x = angles[0] * 360\n",
    "    y = angles[1] * 360\n",
    "    z = angles[2] * 360\n",
    "\n",
    "\n",
    "    # See where the user's head tilting\n",
    "    if y < -10:\n",
    "        text = [0,0,1,0,0]\n",
    "    elif y > 10:\n",
    "        text = [0,0,0,1,0]\n",
    "    elif x < -10:\n",
    "        text = [0,1,0,0,0]\n",
    "    elif x > 10:\n",
    "        text = [0,0,0,0,1]\n",
    "    else:\n",
    "        text = [1,0,0,0,0]\n",
    "\n",
    "    gaze_row = list(np.array([x, y ,z]))+list(text)\n",
    "    gaze_column = list(np.array([\"g_x\", \"g_y\", \"g_z\",\"Forward\",\"Looking Down\",\"Looking Left\",\"Looking Right\",\"Looking Up\"]))\n",
    "    \n",
    "    return gaze_row, gaze_column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee969d2-9759-4676-8cd5-3c533a32d81b",
   "metadata": {},
   "source": [
    "## Funciones para extraer las AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfb38cf5-6032-405c-9923-2aa69858653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proyeccion(image,mascara,results):\n",
    "    x = []\n",
    "    y=[]\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    height, width, _ = image.shape\n",
    "    #Inicializamos el método con imagenes en este caso van a ser fijas para extraer los entrenamientos\n",
    "    if results.face_landmarks is not None:\n",
    "        for index in results.face_landmarks.landmark:\n",
    "            x.append(index.x*width) \n",
    "            y.append(index.y*height)\n",
    "        for index in mascara:\n",
    "            X.append(x[index])\n",
    "            Y.append(y[index])\n",
    "    return X,Y\n",
    "def procesamiento(img,results):\n",
    "    mascara_centro_ojos=[159,145,33,133,386,374,362,263] #Máscara para conseguir el punto central del ojo\n",
    "    mascara_cara_superior=[177]\n",
    "    mascara_cara_inferior=[227]\n",
    "    mascara_recorte=[10,152,454,234]\n",
    "    \n",
    "    #ROTACIÓN BASADA EN OJOS\n",
    "    x,y=proyeccion(img,mascara_centro_ojos,results) #Nos devuelve los puntos en la imagen con face mesh\n",
    "    ojo_izquierdo=[(x[0]+x[1])/2,(y[2]+y[3])/2] #Conseguimos el punto central de los ojos izquierdo y derecho\n",
    "    ojo_derecho=[(x[4]+x[5])/2,(y[6]+y[7])/2]\n",
    "    #print('La mascara ojos funciona correctamente')\n",
    "    #Calculamos la pendiente y ángulo entre los puntos centrales para enderezar la imagen\n",
    "    pendiente= (ojo_derecho[1]-ojo_izquierdo[1])/(ojo_derecho[0]-ojo_izquierdo[0])\n",
    "    angulo=(180/math.pi)*math.atan(pendiente)\n",
    "    rows, cols = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angulo, 1)\n",
    "    img_rotated = cv2.warpAffine(img, M, (cols,rows)) #Aquí ya tenemos la imagen rotada\n",
    "    \n",
    "      #RECORTE CARA BASADA EN 4 PUNTOS\n",
    "    x,y=proyeccion(img_rotated,mascara_recorte,results)\n",
    "    recorte_x_derecha=np.max(x)\n",
    "    recorte_x_izquierda=np.min(x)\n",
    "    recorte_y_arriba=np.min(y)\n",
    "    recorte_y_abajo=np.max(y)\n",
    "    nueva_imagen=img_rotated[int(recorte_y_arriba):int(recorte_y_abajo),int(recorte_x_izquierda):int(recorte_x_derecha)]\n",
    "    \n",
    "    #Normalizamos la imagen en tamaño \n",
    "    nueva_imagen=cv2.resize(nueva_imagen, (100, 100), interpolation=cv2.INTER_LINEAR)\n",
    "    return nueva_imagen\n",
    "def modulo_visualizacion_de_resultados(img,Predictores,pca_pipe_1,pca_pipe_2):\n",
    "    \n",
    "    #Recibo la imagen y le saco las HOGs\n",
    "    feature_1=pd.DataFrame(hog(img, orientations=8, pixels_per_cell=(15, 15), cells_per_block=(2, 2),block_norm='L2-Hys', visualize=False, transform_sqrt=False,feature_vector=True,channel_axis=-1))\n",
    "   \n",
    "    #Recibo la imagen y le saco las LBP\n",
    "    image=rgb2gray(img)\n",
    "    lbp = local_binary_pattern(image, 8, 4, 'default')\n",
    "    values, bins = np.histogram(lbp, bins=np.arange(257))\n",
    "    feature_2=pd.DataFrame(values)\n",
    "    feature_2=feature_2.apply(lambda x: np.log(x+1))\n",
    "    \n",
    "    #Reduzco la dimensionalidad\n",
    "    feature_1=pca_pipe_1.transform(feature_1.T)[0][0:6*19]\n",
    "    feature_2=pca_pipe_2.transform(feature_2.T)[0][0:6*26]\n",
    "    df1=pd.concat([pd.DataFrame(feature_1).T,pd.DataFrame(feature_2).T],axis=1)\n",
    "    Potencia=np.array([math.floor(10*(x.predict_proba([df1.values[0]])[0][1])) for x in Predictores])\n",
    "    return Potencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a371895-21aa-4c6f-a7a7-a3095a397049",
   "metadata": {},
   "source": [
    "## Carga de modelos predictores para AU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f4b500-5d80-42ee-932a-7f24c9be1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"AU_modelos_listados por orden.pickle\", \"rb\") as f:\n",
    "    lista_AU = pickle.load(f)\n",
    "with open(\"au_predictores.pickle\", \"rb\") as f:\n",
    "    predictores = pickle.load(f)\n",
    "with open(\"pca_pipe1.pickle\", \"rb\") as f:\n",
    "    pca_pipe_1 = pickle.load(f)\n",
    "with open(\"pca_pipe2.pickle\", \"rb\") as f:\n",
    "    pca_pipe_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1efb8-2de7-4537-a99e-fac5ee97bcc0",
   "metadata": {},
   "source": [
    "## Script de extracciòn y preprocesamiento de datos para obtencion de archivo .CSV con Face y Pose Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6d138f-a8af-4319-bd44-9a2a95f16926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100011002.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n",
      "1100011003.avi\n",
      "Ignoring empty camera frame.\n",
      "58.38975238800049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inicio = time.time()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "lista_AU=list(lista_AU)\n",
    "lista_frame=pd.Series(index = lista_AU)\n",
    "lista_final=[]\n",
    "contenido=os.listdir('Train/')\n",
    "dft=pd.DataFrame()\n",
    "timeRate = 0.1\n",
    "\n",
    "listaclip=[\"ClipID\"]\n",
    "#path=(\"pruebav.mp4\")\n",
    "for ttv in contenido:\n",
    "    users = os.listdir('Train/'+ttv+'/')\n",
    "    for user in users:\n",
    "        currUser = os.listdir('Train/'+ttv+'/'+user+'/')\n",
    "        clip = os.listdir('Train/'+ttv+'/'+user+'/')[0]\n",
    "        path = os.path.abspath('.')+'/Train/'+ttv+'/'+user+'/'   \n",
    "        try:\n",
    "            print(clip)\n",
    "            cap = cv2.VideoCapture(path+clip) #+clip\n",
    "            FPS = cap.get(5)\n",
    "            c = 1\n",
    "            with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5, refine_face_landmarks=True) as holistic:\n",
    "                while cap.isOpened():\n",
    "                    success, image = cap.read()\n",
    "                    if not success:\n",
    "                        print(\"Ignoring empty camera frame.\")\n",
    "                    # If loading a video, use 'break' instead of 'continue'.\n",
    "                        break \n",
    "                    #image = cv2.imread('20190622_124921.jpg')\n",
    "                    # Convert BGR to RGB\n",
    "                    frameRate = int (FPS) * timeRate\n",
    "                    if(c % frameRate == 0):\n",
    "                        results = holistic.process(image)\n",
    "                        # A CADA FRAME LE HAGO UN PROCESAMIENTO PARA RECORTAR LA CARA CON LAS FUNCIONES PROYECCION Y PREPROCESAMIENTO A PARTIR DE RESULTS DE HOLISTIC\n",
    "                        IMAGEN_PROCESADA=procesamiento(image,results)\n",
    "                        #AQUI EXTRAEMOS LAS FEATURES Y SE LAS DAMOS A LOS PREDICTORES\n",
    "                        potencia=modulo_visualizacion_de_resultados(IMAGEN_PROCESADA,predictores,pca_pipe_1,pca_pipe_2)\n",
    "                        lista_frame=pd.concat([lista_frame,pd.DataFrame(potencia,index=lista_AU)],axis=1)\n",
    "\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                        image.flags.writeable = False\n",
    "                        # Make detections\n",
    "                        results = holistic.process(image)\n",
    "\n",
    "                        # Conver back to BGR\n",
    "                        image.flags.writeable = True\n",
    "                        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                        # Export coordinate and estimate\n",
    "                        #try:\n",
    "                            # Extract gaze\n",
    "                        gaze = results.face_landmarks.landmark\n",
    "                        gaze_row, gaze_column= gazes(image,gaze)\n",
    "\n",
    "                        # Extract pose landmark\n",
    "                        pose = results.pose_landmarks.landmark\n",
    "                        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z] #, landmark.visibility\n",
    "                                                            for landmark in pose]).flatten())\n",
    "                        pose_colum = list(np.array([[\"px_\" + str(index), \"py_\" + str(index), \"pz_\" + str(index)] #, \"pv_\" + str(index)\n",
    "                                                    for index, landmark in enumerate(pose)]).flatten())\n",
    "\n",
    "\n",
    "                        # Extract face landmark\n",
    "                        face = results.face_landmarks.landmark\n",
    "                        face_row = list(np.array([[landmark.x, landmark.y, landmark.z] #, landmark.visibility\n",
    "                                                            for landmark in face]).flatten())\n",
    "\n",
    "                        face_colum = list(np.array([[\"fx_\" + str(index), \"fy_\" + str(index), \"fz_\" + str(index)] #, \"fv_\" + str(index)\n",
    "                                                    for index, landmark in enumerate(face)]).flatten())\n",
    "\n",
    "                        # # Concatenate rows\n",
    "                        ClipID=[clip]\n",
    "                        row = pose_row+face_row+gaze_row+ list(potencia)+ ClipID\n",
    "                        columns_names = pose_colum + face_colum + gaze_column + lista_AU +listaclip\n",
    "\n",
    "                        X = pd.DataFrame([row])\n",
    "                        X.columns = columns_names\n",
    "                        X=X.drop(X.columns[30:99],axis=1)\n",
    "                        dft=pd.concat([dft,X],ignore_index=True)\n",
    "                    c += 1\n",
    "\n",
    "                        #except Exception as e: \n",
    "                         #   print(e)               \n",
    "                          #  pass\n",
    "        except Exception as e:\n",
    "            print(e) \n",
    "            pass\n",
    "fin = time.time()\n",
    "print(fin-inicio)\n",
    "dft.to_csv (\"TestDataset2/\"+\"pruebaxframe\"+\".csv\", index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
